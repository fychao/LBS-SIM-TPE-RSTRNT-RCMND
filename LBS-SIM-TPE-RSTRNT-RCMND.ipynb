{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Start pylab inline mode, so figures will appear in the notebook\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# include libs #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from zpickle import *\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import collections\n",
    "import operator\n",
    "import random\n",
    "import chilin\n",
    "from joblib import Parallel, delayed\n",
    "from gensim import corpora, models, similarities\n",
    "from pprint import pprint\n",
    "from itertools import cycle\n",
    "import pylab as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fn = \"./zobj/ALL_DATA_183340.zobj\"\n",
    "# oData = load(fn)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "attrs = load(\"./zobj/shops_attr_183340.zobj\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "stat = {}\n",
    "for ele in oData:\n",
    "    if not stat.has_key(ele['domain']):\n",
    "        stat[ ele['domain'] ] = {}\n",
    "    if not stat[ ele['domain'] ].has_key(ele['shop_id']):\n",
    "        stat[ ele['domain'] ][ ele['shop_id'] ] = []\n",
    "    if attrs.has_key( ele['shop_id'] ) and attrs[ ele['shop_id'] ].has_key('addr'):\n",
    "        addr = attrs[ ele['shop_id'] ]['addr']\n",
    "        if re.match(u\"^台北市\", addr):\n",
    "            stat[ ele['domain'] ][ ele['shop_id'] ].append(ele)\n",
    "    else:\n",
    "        print ele['shop_id']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "wanted_opn = []\n",
    "shops = []\n",
    "for domain in stat.keys():\n",
    "    for shop in stat[domain]:\n",
    "        pos_num = 0\n",
    "        neg_num = 0\n",
    "        tmp_opn = []\n",
    "        for opn in stat[domain][shop]:\n",
    "            if int(opn['stat_mvalue']) > 50:\n",
    "                pos_num += 1\n",
    "            elif int(opn['stat_mvalue']) <= 40:\n",
    "                neg_num += 1\n",
    "            tmp_opn.append(opn)\n",
    "        if pos_num > 5 and neg_num > 5:\n",
    "            shops.append(shop)\n",
    "            wanted_opn.extend( tmp_opn )\n",
    "            \n",
    "print len(wanted_opn)\n",
    "print \"shops:\", len(shops)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print attrs[wanted_opn[0]['shop_id']]['addr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看餐廳的地理參數"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "uniq_shop = list(set([ x['shop_id'] for x in wanted_opn]))\n",
    "print len(uniq_shop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chinese NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class zTags():\n",
    "    ''' 所有的 POS TAG 元素 '''\n",
    "    @staticmethod\n",
    "    def getEol():\n",
    "        EOLS = [\n",
    "            \"FW\",\n",
    "            \"QUESTIONCATEGORY\",\n",
    "            \"COLONCATEGORY\",\n",
    "            \"COMMACATEGORY\",\n",
    "            \"DASHCATEGORY\",\n",
    "            \"ETCCATEGORY\",\n",
    "            \"PARENTHESISCATEGORY\",\n",
    "            \"PAUSECATEGORY\",\n",
    "            \"PERIODCATEGORY\",\n",
    "            \"QUESTIONCATEGORY\",\n",
    "            \"SEMICOLONCATEGORY\",\n",
    "            \"EXCLANATIONCATEGORY\",\n",
    "            \"EXCLAMATIONCATEGORY\",\n",
    "            \"BR\",\n",
    "            \"SPCHANGECATEGORY\"]\n",
    "        return set(EOLS)\n",
    "    \n",
    "    @staticmethod\n",
    "    def isEol(tag):\n",
    "        EOLS = zTags.getEol()\n",
    "        return True if tag in EOLS else False\n",
    "        \n",
    "    ''' 過濾出不要的標記 '''\n",
    "    @staticmethod\n",
    "    def isWant(tag):\n",
    "        NOT_WANT = [\"^P\", \"^C\", \"^D\", \"^N[c|d|e|f|g|h]\", \"V_2\", \"^T\", \"^SHI\"]\n",
    "        NOT_WANT.extend(zTags.getEol())\n",
    "        flg = True\n",
    "        NOT_WANT = set(NOT_WANT)\n",
    "        for ele in NOT_WANT:\n",
    "            if re.match(ele, tag):\n",
    "                flg = False\n",
    "        return flg\n",
    "                \n",
    "    @staticmethod\n",
    "    def isNot(word):\n",
    "        ''' 否定句 '''\n",
    "        # \"但是\", \"但\", \n",
    "        NOTS = [u\"不\", u\"沒有\", u\"不要\", u\"不能\", u\"沒\", u\"沒有\", u\"無\", u\"不會\", u\"難\", u\"算不上\", u\"未\"]\n",
    "        NOTS = set(NOTS)\n",
    "        return True if word in NOTS else False\n",
    "        \n",
    "    @staticmethod\n",
    "    def notMorph(word):\n",
    "        '''帶否定語素'''\n",
    "        NOTs = u\"^[不|難|沒|未]\"\n",
    "        return re.sub(NOTs, \"\", word) if re.match(NOTs, word) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class zWord():\n",
    "    ''' 基本單詞元素 '''\n",
    "    def __init__(self, word, go_prev=None, go_next=None):\n",
    "        self.org = word\n",
    "        (word, tag) = zWord.toElements(word)\n",
    "        self.word = word\n",
    "        \n",
    "        self.tag = tag\n",
    "        \n",
    "        ''' 設定 wanted '''\n",
    "        self.wanted = zTags.isWant(tag)\n",
    "        \n",
    "        ''' 設定 ORI '''\n",
    "        if zTags.isNot(self.word):\n",
    "            self.ori = 0\n",
    "            self.wanted = False\n",
    "        else:\n",
    "            self.ori = 1\n",
    "\n",
    "        # 詞中有否定\n",
    "        self._selfNot()\n",
    "            \n",
    "        # 取得最佳表達式\n",
    "        self.word_best = self.get_best()\n",
    "\n",
    "        \n",
    "    def get_best(self):\n",
    "        \"\"\"\n",
    "            取得最好的表達式， 例如： \"不\" -> \"\"； \"不用\" -> \"用-\"\n",
    "        \"\"\"\n",
    "        if not self.wanted:\n",
    "            # 詞類不要\n",
    "            return \"\"\n",
    "        if self.ori == 0:\n",
    "            # 否定字組\n",
    "            return \"\"\n",
    "        \n",
    "        return self.word.replace(\"-\", \"\") if self.ori > 0 else self.word.replace(\"-\", \"\")+u\"-\" \n",
    "    \n",
    "    def _selfNot(self):\n",
    "        '''詞中帶有否定'''\n",
    "        if not zTags.isNot(self.word) and zTags.notMorph(self.word): # 要改這裡\n",
    "            if not len(self.word) == 1: # 要改這裡\n",
    "                '''多語素'''\n",
    "                self.ori = 0\n",
    "                # 帶\"不\"頭\n",
    "                self.word = zTags.notMorph(self.word)\n",
    "                self.wanted = True\n",
    "            else:\n",
    "                '''單語素'''\n",
    "                self.ori = 0\n",
    "                self.word = \"\"\n",
    "                self.wanted = False\n",
    "        \n",
    "    ''' Toggle Negative '''\n",
    "    def toggle(self):\n",
    "        if self.ori == 1:\n",
    "            self.ori =-1 \n",
    "        elif self.ori ==-1:\n",
    "            self.ori = 1 \n",
    "        \n",
    "        \n",
    "    ''' 分開 tag 與 word '''\n",
    "    @staticmethod\n",
    "    def toElements(word):\n",
    "        eles = word.replace(u\")\", u\"\").split(u\"(\")\n",
    "        if len(eles)==2:\n",
    "            return (eles[0], eles[1])\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"[%s] %s(%s:%s:%s)\"%(self.__class__.__name__, \n",
    "                              self.word_best.encode(\"utf8\"),\n",
    "                              self.tag.encode(\"utf8\"),\n",
    "                              self.ori,\n",
    "                              self.wanted\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class zSentence:\n",
    "    ''' NOTE: 引入的 stn 一定要先用 toWords 切開\n",
    "        單句元素，會包 zWord \n",
    "    '''\n",
    "    def __init__(self, stn):\n",
    "        if type(stn)==type([]):\n",
    "            self.stn_org = stn\n",
    "        if type(stn)==type(u\"\"):\n",
    "            self.stn_org = zSentence.toWords(stn)\n",
    "        self.proc()\n",
    "\n",
    "    \"\"\" 處理評論句子內容 \"\"\"\n",
    "    def proc(self):\n",
    "        words = []\n",
    "        \n",
    "        for word in self.stn_org:\n",
    "            words.append( zWord(word) )\n",
    "            \n",
    "        self.words = words\n",
    "        \n",
    "        self.notOperation()\n",
    "        \n",
    "#         self._define_bigrams()\n",
    "\n",
    "#     def get_bigrams(self, with_best=False, is_radicals=False):\n",
    "#         if with_best :\n",
    "#             if is_radicals:\n",
    "#                 return self.bigrams_best_radical\n",
    "#             else:\n",
    "#                 return self.bigrams_best\n",
    "#         else:\n",
    "#             if is_radicals:\n",
    "#                 return self.bigrams_radical\n",
    "#             else:\n",
    "#                 return self.bigrams \n",
    "        \n",
    "#     def _define_bigrams(self, n=5, with_best=False):\n",
    "#         skipWindow = zSentence.skipWindow\n",
    "#         self.bigrams_best = set([(tuples[0].get_best(), tuples[1].get_best()) for tuples in skipWindow(self.words, n) if tuples[0].wanted and tuples[1].wanted and not tuples[0].word == tuples[1].word])\n",
    "#         self.bigrams = set([(tuples[0].word, tuples[1].word) for tuples in skipWindow(self.words, n) if tuples[0].wanted and tuples[1].wanted and not tuples[0].word == tuples[1].word])\n",
    "        \n",
    "#         self.bigrams_best_radical = set([ (term2Radi(x), term2Radi(y)) for (x,y) in self.bigrams_best ])\n",
    "#         self.bigrams_radical = set([ (term2Radi(x), term2Radi(y)) for (x,y) in self.bigrams ])\n",
    "        \n",
    "    def get_words(self):\n",
    "        return [ wrd for wrd in self.words] \n",
    "    \n",
    "    def get_wanted(self):\n",
    "        ''' 取得需要的字元 '''\n",
    "        return [ wrd for wrd in self.words if wrd.wanted]\n",
    "        \n",
    "    def notOperation(self):\n",
    "        \"\"\" 否定句處理 \"\"\"\n",
    "        for idx in range(len(self.words)):\n",
    "            if self.words[idx].ori == 0:\n",
    "                for idy in range(idx, len(self.words)):\n",
    "                    self.words[idy].toggle()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"[%s] Words:%s\"%(self.__class__.__name__, len(self.words)) \n",
    "        \n",
    "    @staticmethod\n",
    "    def toWords(stn):\n",
    "        ''' 開成字段 '''\n",
    "        if re.search(u\"　\", stn):\n",
    "            return stn.split(u\"　\")\n",
    "        if re.search(u\" \", stn):\n",
    "            return stn.split(u\" \")\n",
    "      \n",
    "    @staticmethod\n",
    "    def skipWindow(seq, max_win=5):\n",
    "        \"\"\"\n",
    "            SKIP Window 算法\n",
    "        \"\"\"\n",
    "        olen = len(seq)\n",
    "        rterms = []\n",
    "        for pivot in range(olen):\n",
    "            left  = (pivot - max_win) if (pivot - max_win) > 0 else 0\n",
    "            right = (pivot + max_win) if (pivot + max_win) < olen else olen\n",
    "\n",
    "            for idx in range(left, right):\n",
    "                if not idx == pivot and (seq[pivot].wanted and seq[idx].wanted):\n",
    "                    \"\"\" 回傳組合，不從順序，從筆劃 \"\"\"\n",
    "                    if len(seq[pivot].word[0]) > 0 and len(seq[idx].word[0]) > 0:\n",
    "                        if seq[pivot].word[0] > seq[idx].word[0]:\n",
    "                            rterms.append( ( seq[pivot], seq[idx] ) ) \n",
    "                        else:\n",
    "                            rterms.append( ( seq[idx], seq[pivot] ) ) \n",
    "\n",
    "        return set(rterms)\n",
    " \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class zOpinion:\n",
    "    \"\"\" 單一評論 \"\"\"\n",
    "    def __init__(self, opn):\n",
    "        self.data = opn\n",
    "        self.stns = []\n",
    "        self.word_only = []\n",
    "        self.proc()\n",
    "        \n",
    "    \"\"\" 處理評論內容 \"\"\"\n",
    "    def proc(self):\n",
    "        stns = zOpinion.toStn(self.data)\n",
    "        for stn in stns:\n",
    "            self.stns.append(zSentence(stn))\n",
    "            \n",
    "        self.stat()\n",
    "        self._doWords4Tag()\n",
    "        \n",
    "    \"\"\" 評論內的字數統計 \"\"\"\n",
    "    def stat(self):\n",
    "        \n",
    "        ''' 單一詞統計 '''\n",
    "        oWords = []\n",
    "        \n",
    "        ''' bigram 統計 '''\n",
    "        oBigrams = []\n",
    "        oRadiBigrams = []\n",
    "        for stn in self.stns:\n",
    "            self.word_only.extend([x.word for x in stn.get_words()])\n",
    "            oWords.extend([ x.word_best for x in stn.get_wanted()])\n",
    "#             oBigrams.extend(stn.get_bigrams())\n",
    "#             oRadiBigrams.extend([ (term2Radi(x), term2Radi(y)) for (x, y) in stn.get_bigrams()])\n",
    "            \n",
    "        # 單一詞結果\n",
    "        self.stat_words = oWords\n",
    "        self.stat_words_dic = collections.Counter(oWords)\n",
    "        \n",
    "        # 雙詞的結果\n",
    "#         self.stat_bigrams = oBigrams\n",
    "#         self.stat_bigrams_dic = collections.Counter(oBigrams)\n",
    "        \n",
    "        # 雙詞的部首\n",
    "#         self.stat_radi_bigram = oRadiBigrams\n",
    "        \n",
    "    def getOrg(self):\n",
    "        return self.data['tagged']\n",
    "        \n",
    "    \"\"\" 取得特定 key 的值 \"\"\"\n",
    "    def get(self, key):\n",
    "        if key in self.getKeys():\n",
    "            return self.data[key]\n",
    "        \n",
    "    def _doWords4Tag(self):\n",
    "        wrds = []\n",
    "        for stn in self.stns:\n",
    "            for word in stn.get_wanted():\n",
    "                wrds.append(word.get_best()) # here\n",
    "        self._stn_words = wrds\n",
    "#         self._stn_radical_pairs = [ term2Radi(x) for x in wrds]\n",
    "\n",
    "    def getWords4Tag(self):\n",
    "        return self._stn_words\n",
    "    \n",
    "    def getRadicalsPair4Tag(self):\n",
    "        return self._stn_radical_pairs\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"[%s] words:%s\"%(self.__class__.__name__, len(self.stat_words_dic.keys()))  \n",
    "\n",
    "        \n",
    "    def getPair(self, wanted_terms):\n",
    "        \"\"\" 取得必要的 pair \"\"\"\n",
    "\n",
    "#         sorted2Terms = lambda x, y: (x, y) if x > y else (y, x)\n",
    "#         isInBigram = lambda x,y: sorted2Terms(x,y) if sorted2Terms(x,y) in self.stat_bigrams_dic.keys() else False\n",
    "\n",
    "        wanted_pairs = [ x for x in self.stat_bigrams_dic.keys() if x[0] in wanted_terms or x[1] in wanted_terms]\n",
    "\n",
    "        return_pairs = []\n",
    "        for stn in self.stns:\n",
    "            stn_terms = list(set([ wrd.word_best for wrd in stn.get_wanted()]))\n",
    "            for pair in wanted_pairs:\n",
    "                size = len(set([ x.replace(\"-\", \"\") for x in stn_terms]).intersection(set(pair)))\n",
    "                if size >= 1:\n",
    "                    org_x = \"\".join([ x for x in stn_terms if x.replace(\"-\", \"\") == pair[0]])\n",
    "                    org_y = \"\".join([ x for x in stn_terms if x.replace(\"-\", \"\") == pair[1]])\n",
    "                    return_pairs.append( \"%s/%s\"%(org_x, org_y) )\n",
    "            \n",
    "        return list(set(return_pairs))\n",
    "    \n",
    "    @staticmethod\n",
    "    def toStn(stn):\n",
    "        ''' 開成字段, [ [word, word], [] ... ] '''\n",
    "        tagged = u\"　 \".join(stn.split(\"\\n\"))\n",
    "        words = zSentence.toWords(tagged)\n",
    "        stns = []\n",
    "        stn = []\n",
    "        for idx in range(len(words)):\n",
    "            ''' 可能會有空字串 '''\n",
    "            try:\n",
    "                (word, tag) = zWord.toElements(words[idx])\n",
    "                stn.append(words[idx])\n",
    "                if zTags.isEol(tag):\n",
    "                    # 如果字串少於1 個字，就跳開\n",
    "                    if len(stn) >1:\n",
    "                        stns.append(stn)\n",
    "                    stn = []\n",
    "            except: \n",
    "                continue\n",
    "        if len(stn) >1:\n",
    "            stns.append(stn)\n",
    "\n",
    "        return stns\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "oCol = []\n",
    "idx = 0\n",
    "rank = []\n",
    "time_start = time.clock()\n",
    "\n",
    "for ele in wanted_opn[:]:\n",
    "    rank.append( ele['stat_mvalue'] )\n",
    "    if (idx%100) == 0:\n",
    "        print idx, \" time: %.2gs\" % (time.clock()-time_start)\n",
    "        time_start = time.clock()\n",
    "\n",
    "    idx += 1\n",
    "    oCol.append(( attrs[ele['shop_id']], \n",
    "                  getChilinTxt(ele['tagged']),\n",
    "                  ele['stat_mvalue'],\n",
    "                  ele['tagged']\n",
    "                ))\n",
    "\n",
    "print collections.Counter(rank)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print len(oCol)\n",
    "save(oCol, \"./zobj/Taipei_shops_comments.zobj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 由此開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oChi = chilin.chilin()\n",
    "\n",
    "def cnv2chilin(wrd):\n",
    "    ''' 使用詞林擴充 '''\n",
    "    tobj = oChi.getHead(wrd.encode(\"utf8\"), 8)\n",
    "    if tobj:\n",
    "        tobj = [ x for x in tobj if (not x[0] in ['A', 'C', 'J', 'K', 'L']) and not x[-1] in ['#']]\n",
    "        if len(tobj)>0:\n",
    "#             print wrd, \" \".join(tobj)\n",
    "            grps = [ [ y.decode(\"utf8\") for y in oChi.getWrd(x)] for x in tobj ] \n",
    "            return set([item for sublist in grps for item in sublist]) # see http://bit.ly/1FrTjwF\n",
    "        return set([wrd])\n",
    "    else:\n",
    "        return set([wrd])\n",
    "    \n",
    "def chilinExt(aSet):\n",
    "    # 使用辭林擴充\n",
    "    ext = set()\n",
    "\n",
    "    if type(aSet) == type(set()):\n",
    "        for x in aSet:\n",
    "            flg = False\n",
    "            if re.search(\"-$\", x):\n",
    "                flg = True\n",
    "\n",
    "            cnvted = cnv2chilin(x.replace(\"-\", \"\"))\n",
    "            ext.update([\"%s\"%x if not flg else \"%s-\"%x for x in cnvted])\n",
    "    elif type(aSet) == type(u\"\"):\n",
    "        flg = False\n",
    "        if re.search(\"-$\", aSet):\n",
    "            flg = True\n",
    "        cnvted = cnv2chilin(aSet.replace(\"-\", \"\"))\n",
    "        ext.update([\"%s\"%x if not flg else \"%s-\"%x for x in cnvted])\n",
    "        \n",
    "    return \" \".join(ext).replace(\"-\", u\"負\")\n",
    "\n",
    "def getChilinTxt(tagged):\n",
    "    opn = zOpinion(tagged)\n",
    "#     print len(opn.stns)\n",
    "    txts = Parallel(n_jobs=-1)(delayed(chilinExt)(set([x.get_best() for x in stn.get_wanted()])) for stn in opn.stns)\n",
    "#     for stn in opn.stns:\n",
    "#         print \" \".join(stn.stn_org)\n",
    "# #         print \" \".join([\"%s, %s\\n\"%(x.get_best(), \" \".join(chilinExt(x.get_best()))) for x in stn.get_wanted()])\n",
    "#         print chilinExt(set([x.get_best() for x in stn.get_wanted()]))\n",
    "        \n",
    "    return \" \".join(txts)\n",
    "# print \" \".join(chilinExt([u\"錯\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oCol = load(\"./zobj/Taipei_shops_comments.zobj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16908\n"
     ]
    }
   ],
   "source": [
    "print len(oCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//1 build dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txts = [ x[1].split(\" \") for x in oCol]\n",
    "dictionary = corpora.Dictionary(txts)\n",
    "dictionary.filter_tokens(bad_ids=[0])\n",
    "dictionary.filter_extremes(no_below=5)\n",
    "dictionary.compactify()\n",
    "len(dictionary.token2id)\n",
    "\n",
    "dictionary.save(\"./zobj/16908_dictionary.mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntusd_hash = load(\"./zobj/NTUSD_HASH_POS_NEG.zobj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65389\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary.load(\"./zobj/16908_dictionary.mm\")\n",
    "print len(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n"
     ]
    }
   ],
   "source": [
    "rank_code = lambda x: \"P\" if int(x)>50 else \"N\"\n",
    "\n",
    "\n",
    "print rank_code(oCol[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5420 11488\n"
     ]
    }
   ],
   "source": [
    "txts_pos = [ x for x in oCol if rank_code(x[2])==\"P\"]\n",
    "txts_neg = [ x for x in oCol if rank_code(x[2])==\"N\"]\n",
    "\n",
    "\n",
    "corpus_pos = [ dictionary.doc2bow(x[1].split(\" \")) for x in txts_pos]\n",
    "corpus_neg = [ dictionary.doc2bow(x[1].split(\" \")) for x in txts_neg]\n",
    "print len(corpus_pos), len(corpus_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('./zobj/Taipei_shop_corpus_pos.mm', corpus_pos)\n",
    "corpora.MmCorpus.serialize('./zobj/Taipei_shop_corpus_neg.mm', corpus_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_pos = models.TfidfModel(corpus_pos)\n",
    "lsi = models.LsiModel(tfidf_pos[corpus_pos], num_topics=200, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.035*\"蛋糕\" + 0.022*\"燔\" + 0.022*\"麵包\" + 0.022*\"拉麵\" + 0.022*\"鬆餅\" + 0.021*\"巧克力\" + 0.021*\"炕\" + 0.021*\"炙\" + 0.021*\"烤\" + 0.021*\"烘製\"\n",
      "0.049*\"蛋糕\" + -0.041*\"可觀負\" + -0.041*\"名不虛傳負\" + -0.041*\"口碑載道負\" + -0.041*\"有口皆碑負\" + -0.041*\"交口稱譽負\" + -0.041*\"上佳負\" + -0.041*\"帥負\" + -0.041*\"名特新優精負\" + -0.041*\"優負\"\n",
      "0.080*\"麻辣\" + 0.080*\"辣味\" + 0.080*\"辛\" + 0.080*\"辣絲絲\" + 0.080*\"辣乎乎\" + 0.080*\"辛辣\" + -0.076*\"蛋糕\" + 0.072*\"拉麵\" + 0.065*\"辣\" + 0.062*\"如狼似虎\"\n",
      "-0.094*\"蛋糕\" + 0.077*\"辣乎乎\" + 0.077*\"辛\" + 0.077*\"辣味\" + 0.077*\"辣絲絲\" + 0.077*\"麻辣\" + 0.076*\"辛辣\" + 0.060*\"鍋\" + 0.058*\"辣\" + 0.052*\"拉麵\"\n",
      "-0.046*\"拉麵\" + -0.043*\"臧負\" + -0.043*\"仁至義盡負\" + -0.043*\"助人為樂負\" + -0.043*\"樂善好施負\" + -0.043*\"善良負\" + -0.043*\"足以負\" + -0.043*\"堪負\" + -0.043*\"得以負\" + -0.043*\"何嘗不可負\"\n",
      "-0.062*\"鬆餅\" + 0.054*\"拳打腳踢\" + 0.054*\"毆\" + 0.054*\"毆鬥\" + 0.054*\"毆打\" + 0.054*\"揮拳\" + 0.053*\"舀\" + 0.053*\"挹\" + 0.052*\"交手\" + 0.052*\"格鬥\"\n",
      "-0.106*\"拉麵\" + -0.065*\"刈\" + -0.065*\"招攬\" + -0.065*\"攬客\" + -0.065*\"招徠\" + -0.065*\"直拉\" + -0.065*\"抻\" + -0.065*\"拉長\" + -0.065*\"拉縴\" + -0.065*\"拉杆\"\n",
      "0.062*\"刈\" + 0.062*\"攬客\" + 0.062*\"招徠\" + 0.062*\"招攬\" + 0.062*\"割\" + 0.061*\"拉杆\" + 0.061*\"拉縴\" + 0.061*\"拉長\" + 0.061*\"抻\" + 0.061*\"拉拉\"\n",
      "0.107*\"蛋糕\" + 0.080*\"辣絲絲\" + 0.080*\"辣乎乎\" + 0.080*\"辛\" + 0.080*\"麻辣\" + 0.080*\"辣味\" + 0.080*\"辛辣\" + 0.059*\"喪心病狂\" + 0.059*\"惡毒\" + 0.059*\"心狠手辣\"\n",
      "0.059*\"別名\" + 0.059*\"別號\" + 0.059*\"別字\" + 0.058*\"如訴如泣\" + 0.058*\"哭叫\" + 0.058*\"鬼哭神嚎\" + 0.058*\"鬼哭狼嚎\" + 0.058*\"痛哭流涕\" + 0.058*\"如泣如訴\" + 0.058*\"哭喪\"\n"
     ]
    }
   ],
   "source": [
    "print \"\\n\".join(lsi.print_topics(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\u8fa3-', u'\\u706b\\u934b-']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mstr = u\"不會(D)　辣(VH)　的(DE)　火鍋(Na)\"\n",
    "# tagged = getPOS(mstr.encode(\"utf8\"))\n",
    "# print tagged\n",
    "# mstr += \" \".join([ x.replace(\"-\", u\"負\") for x in ntusd_hash[\"NEG\"]])\n",
    "zOpinion(mstr).getWords4Tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "辣負 火鍋負\n"
     ]
    }
   ],
   "source": [
    "proc_txt = [ x.replace(\"-\", u\"負\") for x in zOpinion(mstr).getWords4Tag()]\n",
    "print \" \".join(proc_txt)\n",
    "mstr_bow = dictionary.doc2bow(proc_txt)\n",
    "vec_lsi = lsi[mstr_bow]\n",
    "sims = index[vec_lsi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'27502-\\u65b0\\u7586\\u9905': {'lat': '25.11255726402854', 'adr': u'\\u53f0\\u5317\\u5e02\\u58eb\\u6797\\u5340\\u58eb\\u6771\\u8def266\\u5df75\\u5f0417\\u865f', 'lon': '121.53759574765395', 'val': [u'55', u'55', u'55']}}\n"
     ]
    }
   ],
   "source": [
    "def clnTxt(mstr):\n",
    "    return \"\".join([ x.split(\"(\")[0] for x in mstr.strip().split(u\"　\") if len( x.split(\"(\") ) >1])\n",
    "\n",
    "\n",
    "shops_weight = {}\n",
    "for x in txts_pos[:3]:\n",
    "    shop_title = x[0]['title']\n",
    "    if not shops_weight.has_key(shop_title):\n",
    "        shops_weight[ shop_title ] = { 'lat': x[0]['latitude'],\n",
    "                                          'lon': x[0]['longitude'],\n",
    "                                          'adr': x[0]['addr'],\n",
    "                                          'val': []}\n",
    "    shops_weight[ shop_title ]['val'].append( x[2])\n",
    "print shops_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    " \n",
    "def distance_on_unit_sphere(lat1, long1, lat2, long2):\n",
    "    # 以 KM 回傳，原程式碼在 http://goo.gl/JExDdc\n",
    "    # 回傳是公里\n",
    "    # Convert latitude and longitude to \n",
    "    # spherical coordinates in radians.\n",
    "    degrees_to_radians = math.pi/180.0\n",
    "         \n",
    "    # phi = 90 - latitude\n",
    "    phi1 = (90.0 - lat1)*degrees_to_radians\n",
    "    phi2 = (90.0 - lat2)*degrees_to_radians\n",
    "         \n",
    "    # theta = longitude\n",
    "    theta1 = long1*degrees_to_radians\n",
    "    theta2 = long2*degrees_to_radians\n",
    "         \n",
    "    # Compute spherical distance from spherical coordinates.\n",
    "         \n",
    "    # For two locations in spherical coordinates \n",
    "    # (1, theta, phi) and (1, theta, phi)\n",
    "    # cosine( arc length ) = \n",
    "    #    sin phi sin phi' cos(theta-theta') + cos phi cos phi'\n",
    "    # distance = rho * arc length\n",
    "     \n",
    "    cos = (math.sin(phi1)*math.sin(phi2)*math.cos(theta1 - theta2) + \n",
    "           math.cos(phi1)*math.cos(phi2))\n",
    "    arc = math.acos( cos )\n",
    " \n",
    "    # Remember to multiply arc by the radius of the earth \n",
    "    # in your favorite set of units to get length.\n",
    "    return arc * 6373\n",
    "\n",
    "def diff_lat_lon(me_loc, target):\n",
    "    return distance_on_unit_sphere(float(me_loc['lat']), float(me_loc['lon']), \n",
    "                                   float(target['lat']), float(target['lon']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.64666186361 0.652716\n",
      ">>看到沒?傳說中的豆腐冰淇淋，真的是超超超超好吃>>滑溜溜的鴨血令人回味無窮，燙在口中暖在心理真的是超美味的啦>>一旁很像飲料的是高湯>>來了來了傳說中的無老鍋，他的麻辣鍋我覺得不辣反而是香麻整體來說真的非常的棒，不過建議四個人去最剛好，因為我跟我朋友兩個人去隨便點一點就吃了２千多塊，貴但是非常值得。\t\t\n",
      "1.09844636177 0.598129\n",
      "一家有歷史的老店不能墨守成規,才不會被潮流所淹沒我在有六十幾年歷史的老店~四川吳抄手~,看見年輕人堅守傳統老味道的同時還勇於創新,開發更多新商品,賦予老店新的生命位於台北忠孝東路上的四川吳抄手,第三代老闆是一位年輕漂亮的小姐,年輕的老闆非常用心,以川菜料理手法研發便利美食~川饌之味~讓無法親臨店內品嚐美食的朋友們隨時都能透過宅配的方式吃到吳抄手的美味很榮幸這次能應黑貓探險隊的邀請讓我有機會品嚐６０年老店的美味首先上桌的是鴛鴦鍋,顛覆了我對鴛鴦鍋的印象,一般的鴛鴦鍋不辣的是白湯底,吳抄手的鍋底,因為是用大骨湯加上三十餘種中式香料採純手工傳統方式炒製,左邊是不辣,右邊是麻辣鍋,辣與不辣的鍋底都一樣,差別只在於辣的有放特製辣油吳抄手的麻辣鍋不叫辣,應該叫麻,連不辣的湯底也會有微微的麻,此麻會讓人很容易接受連麻辣鍋也是如此,它是麻喔不是辣,我對麻辣鍋並不是特敢吃,對於吳抄手的麻辣鍋卻很容易接受羊肩肉雪花豬牛小排特製沾醬=黑色的是麻辣醬,黃色的沾醬,它叫麻蛋,是高級麻油加上新鮮蛋黃攪拌而成,只有老饕才知道的喔,沾法是先沾麻辣醬讓肉有鹹味)再沾麻蛋讓肉質更滑嫩)特製滷花生=花生是廚師獨門料理,它是用豬皮下去滷製,會讓花生顯的油油亮亮的從外觀看起來很鹹,實際上並不鹹,還會讓人欲罷不能烏梅汁也是店家的獨門配方,外面的烏梅汁是鹹的不得了,吳抄手的是會讓人回甘,目前還沒有推宅配,只因第二代傳人,堅持要找到合適的瓶子才要推出宅配這些丸類大都是自家工廠生產真的是真材實料,與外面吃的丸類差別很大的,即使久煮也不會影響到口感,表示吳抄手的魚漿是用頂級材料,像花枝腸就真的吃到整塊花枝吳抄手的火鍋,是用炭火烹調,店家說保溫效果較好只是我們習慣用瓦斯爐火以方便調整火侯,但是勒~用炭火無法調整火侯的大小,一時間還真不習慣,老是想用手去關火吃到最後,還能用麵條下去煮麵條也是店家特製的)白麵條的香,裹滿麻辣湯汁的香,確實好吃店家的招牌菜=紅油抄手就是乾餛飩)老饕必點~紅油餃紅油抄手=皮薄,豬肉餡清香,不會油膩紅油餃=皮較厚,吃起來有口感之前店家有供應飯後甜點都是手工製作),因毒奶事件,把甜點改成綠豆薏仁湯吳抄手鍋底的價格以上的出菜量是以當天到場人數由廚師統籌配菜,並非正常的出菜量老店真的有它的魅力之處,當天用餐時還巧遇陳昇一家人在用餐,隔壁桌還是一桌的日本人當天還是星期一,整間餐廳坐了九分滿,第三代傳人還是不斷的想要創新,不想讓老店只是一直維持傳統,還想讓老店更好,由此可見傳人的用心吳抄手第三代傳人的想法與做法,可供一些只懂維持不懂創新的老店作為參考\n",
      "5.77091205384 0.5662\n",
      "鍋大爺~超有特色的蒙古火鍋,不管是清湯或麻辣鍋底都超好吃!湯底裡面都有５種以上的中藥材,感覺上冬天來去吃很補身子!食材方面也很新鮮店家號稱有１０１種食材肉內都是現沏的冷凍肉品最特別的是有類似莎威瑪的燒烤無限供應整家餐廳的氣氛跟裝潢真的很棒我最喜歡的是他的類似殺位碼的烤肉因為肉上有加上孓然粉超香的~雖然我不敢吃辣但是他那ㄍ肉就超划算的啦\n"
     ]
    }
   ],
   "source": [
    "me_loc = { 'lat': 25.041171, \"lon\":121.565227}\n",
    "for (x,y) in sorted(enumerate(sims), key=lambda item: -item[1])[:3]:\n",
    "    target = { 'lat': txts_pos[x][0]['latitude'], 'lon': txts_pos[x][0]['longitude'] }\n",
    "    \n",
    "    print diff_lat_lon(me_loc, target), y\n",
    "    print clnTxt(txts_pos[x][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依照店家建立相似度模型後，將特別的字詞與 NTUSD align，最後推出合適的店家。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 地理位置計算 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib2\n",
    "import json\n",
    "\n",
    "\n",
    "params = {'address': '台北市政府','sensor': 'false'}\n",
    "url = 'http://maps.googleapis.com/maps/api/geocode/json?' + urllib.urlencode(params)\n",
    "rawreply = urllib2.urlopen(url).read()\n",
    "result = json.loads(rawreply)\n",
    "\n",
    "lat, lng = [(s['formatted_address'],s['geometry']) for s in result['results']][0][1][u'location'].values()\n",
    "print lat, lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_on_unit_sphere(23.5852855, 119.61, 23.5852855, 119.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
